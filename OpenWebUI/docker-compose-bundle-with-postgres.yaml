services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:latest-cuda
    container_name: open-webui
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://localhost:11434
      - ENABLE_OPENAI_API=False
      - WEBUI_NAME=GlassHouse
      - USE_CUDA_DOCKER=True
      - VECTOR_DB=qdrant
      - QDRANT_URI=http://localhost:6333
      - ENABLE_QDRANT_MULTITENANCY_MODE=True
      - CONTENT_EXTRACTION_ENGINE=docling
      - DOCLING_SERVER_URL=http://localhost:5001
      - DOCLING_OCR_ENGINE=tesseract
      - DOCLING_OCR_LANG=eng,tur
      - GLOBAL_LOG_LEVEL=DEBUG
      - RAG_EMBEDDING_ENGINE=ollama
      - RAG_EMBEDDING_MODEL=bge-m3:567m
      - RAG_TOP_K=10
      - RAG_TOP_K_RERANKER=5
      - RAG_EMBEDDING_BATCH_SIZE=10
      - CHUNK_SIZE=2000
      - CHUNK_OVERLAP=200
      - RAG_TEXT_SPLITTER=token
      - RAG_EMBEDDING_BATCH_SIZE=30
      - ENABLE_CODE_EXECUTION=False
      - ENABLE_WEB_SEARCH=True
      - WEB_SEARCH_RESULT_COUNT=3
      - WEB_SEARCH_ENGINE=searxng
      - SEARXNG_QUERY_URL=http://localhost:4000/search?q=<query>
      - ENABLE_EVALUATION_ARENA_MODELS=False
      - ENABLE_CODE_INTERPRETER=False
      - ENABLE_CODE_EXECUTION=False
      - DEFAULT_USER_ROLE=pending
      - ENABLE_SIGNUP_PASSWORD_CONFIRMATION=True
      - MCP_ENABLE=True
      - DATABASE_URL=postgresql://openwebui:${DB_PASS}@localhost:5432/openwebui

    network_mode: host
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
    volumes:
      - qdrant-storage:/qdrant/storage
    networks:
      - webui-net

  docling-serve:
    image: ghcr.io/docling-project/docling-serve-cu128:main
    container_name: docling-serve
    ports:
      - "5001:5001"
    environment:
      DOCLING_SERVE_ENABLE_UI: "true"
      NVIDIA_VISIBLE_DEVICES: "all"
    runtime: nvidia
    restart: unless-stopped
    networks:
      - webui-net

  vllm-reranker:
    image: vllm/vllm-openai:v0.10.2
    container_name: vllm-reranker
    runtime: nvidia
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "9001:9001"
    networks:
      - webui-net
    ipc: host
    command: |
      --model BAAI/bge-reranker-v2-m3
      --gpu-memory-utilization 0.3
      --host 0.0.0.0
      --port 9001
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  vllm-gpt:
    image: vllm/vllm-openai:v0.10.2
    container_name: vllm-gpt
    runtime: nvidia
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "9002:9002"
    networks:
      - webui-net
    ipc: host
    command: |
      --model openai/gpt-oss-20b
      --gpu-memory-utilization 0.6
      --host 0.0.0.0
      --port 9002
      --max-model-len 64000
      --max-num-seqs 128
      --async-scheduling
      --api-key 123456
      --enable-auto-tool-choice
      --tool-call-parser openai
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  open-webui-data:
  qdrant-storage:

networks:
  webui-net:
    name: webui-net
