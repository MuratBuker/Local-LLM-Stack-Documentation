services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:latest-cuda
    container_name: open-webui
    volumes:
      - open-webui-data:/app/backend/data
    environment:
          # Ollama connection
          OLLAMA_BASE_URL: http://host.docker.internal:11434
          # vLLM connection
          ENABLE_OPENAI_API: "True"
          OPENAI_API_BASE_URL: http://vllm-gpt:9002/v1
          # Web UI settings
          WEBUI_NAME: GlassHouse
          WEBUI_URL: https://opn.lotus.net.tr
          CORS_ALLOW_ORIGIN: https://opn.lotus.net.tr
          # Enable CUDA
          USE_CUDA_DOCKER: "True"
          # Disable API for Open-WebUI for security
          ENABLE_API_KEY: "False"
          # Use Qdrant as vector DB
          VECTOR_DB: qdrant
          QDRANT_URI: http://qdrant:6333
          ENABLE_QDRANT_MULTITENANCY_MODE: "True"
          # Use Docling for extraction
          CONTENT_EXTRACTION_ENGINE: docling
          DOCLING_SERVER_URL: http://docling-serve:5001
          DOCLING_OCR_ENGINE: tesseract
          DOCLING_OCR_LANG: eng,tur
          # Log level info or debug
          GLOBAL_LOG_LEVEL: INFO
          # RAG embedding settings
          RAG_ALLOWED_FILE_EXTENSIONS: '["pdf,docx,doc,txt,md,pptx,xls,xlsx,csv,epub,html,htm,xml,json,yaml,yml"]'
          RAG_EMBEDDING_ENGINE: ollama
          RAG_EMBEDDING_MODEL: qwen3-embedding:0.6b
          RAG_OLLAMA_BASE_URL: http://host.docker.internal:11434
          RAG_TOP_K: 10
          RAG_TOP_K_RERANKER: 5
          RAG_EMBEDDING_BATCH_SIZE: 500
          CHUNK_SIZE: 1500
          CHUNK_OVERLAP: 100
          ENABLE_RAG_HYBRID_SEARCH: "True"
          RAG_TEXT_SPLITTER: token
          # RAG Reranker settings
          RAG_RERANKING_ENGINE: external
          RAG_EXTERNAL_RERANKER_URL: http://vllm-qwen3-reranker-06b:9001/rerank
          RAG_RERANKING_MODEL: Qwen/Qwen3-Reranker-0.6B
          # Disable some features for security
          ENABLE_CODE_EXECUTION: "False"
          ENABLE_WEB_SEARCH: "False"
          ENABLE_EVALUATION_ARENA_MODELS: "True"
          ENABLE_CODE_INTERPRETER: "False"
          # TTS Config
          AUDIO_TTS_ENGINE: "openai"
          AUDIO_TTS_MODEL: "kokoro"
          AUDIO_TTS_VOICE: "af_bella" # You can change to various voice
          AUDIO_TTS_OPENAI_API_BASE_URL: "http://host.docker.internal:8880/v1"
          AUDIO_TTS_OPENAI_API_KEY: 123456 # Will not be used, enter anything
          # User signup settings
          DEFAULT_USER_ROLE: pending
          ENABLE_SIGNUP_PASSWORD_CONFIRMATION: "True"
          # New parameter, enable MCP
          MCP_ENABLE: "True"
          # Reducing VRAM usage
          ENABLE_AUTOCOMPLETE_GENERATION: "False"
          # Using PostgreSQL
          DATABASE_URL: postgresql://openwebui:${DB_PASS}@host.docker.internal:5432/openwebui
          # External mcp tools
          TOOL_SERVER_CONNECTIONS: '[{"name": "Netbox", "url": "http://host.docker.internal:8009/netbox"},{"name": "Time", "url": "http://host.docker.internal:8009/time"},{"name": "Searxng", "url": "http://host.docker.internal:8009/searxng"},{"name": "Wikipedia", "url": "http://host.docker.internal:8009/wikipedia"},{"name": "GHOS", "url": "http://host.docker.internal:8009/glasshouse"}]'
    ports:
    - "8080:8080"
    networks:
      - webui-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
    volumes:
      - qdrant-storage:/qdrant/storage
    networks:
      - webui-net

  docling-serve:
    image: ghcr.io/docling-project/docling-serve-cu128:main
    container_name: docling-serve
    ports:
      - "5001:5001"
    environment:
      DOCLING_SERVE_MAX_SYNC_WAIT: 720
      DOCLING_SERVE_ENABLE_UI: "true"
      NVIDIA_VISIBLE_DEVICES: "all"
    runtime: nvidia
    restart: unless-stopped
    networks:
      - webui-net

  vllm-qwen3-reranker-06b:
    image: vllm/vllm-openai:v0.10.2
    container_name: vllm-qwen3-reranker-06b
    runtime: nvidia
    restart: unless-stopped
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "9001:9001"
    networks:
      - webui-net
    ipc: host
    command: |
      --model Qwen/Qwen3-Reranker-0.6B
      --gpu-memory-utilization 0.2
      --host 0.0.0.0
      --port 9001
      --max-model-len 16000
      --cpu-offload-gb 10
      --hf_overrides '{"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'  
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  vllm-gpt:
    image: vllm/vllm-openai:v0.10.2
    container_name: vllm-gpt
    runtime: nvidia
    restart: unless-stopped
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "9002:9002"
    networks:
      - webui-net
    ipc: host
    command: |
      --model openai/gpt-oss-20b
      --gpu-memory-utilization 0.55
      --host 0.0.0.0
      --port 9002
      --max-model-len 32000
      --max-num-seqs 128
      --async-scheduling
      --enable-auto-tool-choice
      --tool-call-parser openai
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      TZ: Europe/Istanbul
      WATCHTOWER_CLEANUP: "true"
      WATCHTOWER_DEBUG: "true"
      WATCHTOWER_SCHEDULE: 0 45 * * * *

  searxng:
    image: docker.io/searxng/searxng:latest
    container_name: searxng
    environment:
      - GRANIAN_PORT=4000
    volumes:
      - /root/searxng:/etc/searxng:rw
    ports:
      - 4000:4000
    networks:
      - webui-net
    restart: unless-stopped

volumes:
  open-webui-data:
  qdrant-storage:

networks:
  webui-net:
    name: webui-net