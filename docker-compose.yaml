services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:latest-cuda
    container_name: open-webui
    volumes:
      - open-webui-data:/app/backend/data
    environment:
          OLLAMA_BASE_URL: http://host.docker.internal:11434
          ENABLE_OPENAI_API: "True"
          OPENAI_API_BASE_URL: http://vllm-gpt:9002/v1
          WEBUI_NAME: GlassHouse
          WEBUI_URL: https://opn.lotus.net.tr
          CORS_ALLOW_ORIGIN: https://opn.lotus.net.tr
          USE_CUDA_DOCKER: "True"
          ENABLE_API_KEY: "False"
          VECTOR_DB: qdrant
          QDRANT_URI: http://qdrant:6333
          ENABLE_QDRANT_MULTITENANCY_MODE: "True"
          CONTENT_EXTRACTION_ENGINE: docling
          DOCLING_SERVER_URL: http://docling-serve:5001
          DOCLING_OCR_ENGINE: tesseract
          DOCLING_OCR_LANG: eng,tur
          GLOBAL_LOG_LEVEL: INFO
          RAG_EMBEDDING_ENGINE: ollama
          RAG_EMBEDDING_MODEL: qwen3-embedding:0.6b
          RAG_OLLAMA_BASE_URL: http://host.docker.internal:11434
          RAG_TOP_K: 10
          RAG_TOP_K_RERANKER: 5
          RAG_EMBEDDING_BATCH_SIZE: 500
          CHUNK_SIZE: 1500
          CHUNK_OVERLAP: 100
          ENABLE_RAG_HYBRID_SEARCH: "True"
          RAG_TEXT_SPLITTER: token
          RAG_RERANKING_MODEL: Qwen/Qwen3-Reranker-0.6B
          ENABLE_CODE_EXECUTION: "False"
          ENABLE_WEB_SEARCH: "False"
          ENABLE_EVALUATION_ARENA_MODELS: "True"
          ENABLE_CODE_INTERPRETER: "False"
          DEFAULT_USER_ROLE: pending
          ENABLE_SIGNUP_PASSWORD_CONFIRMATION: "True"
          MCP_ENABLE: "True"
          ENABLE_AUTOCOMPLETE_GENERATION: "False"
          DATABASE_URL: postgresql://openwebui:${DB_PASS}@host.docker.internal:5432/openwebui
          TOOL_SERVER_CONNECTIONS: '[{"name": "Netbox", "url": "http://host.docker.internal:8009/netbox"},{"name": "Time", "url": "http://host.docker.internal:8009/time"},{"name": "Searxng", "url": "http://host.docker.internal:8009/searxng"},{"name": "Wikipedia", "url": "http://host.docker.internal:8009/wikipedia"},{"name": "GHOS", "url": "http://host.docker.internal:8009/glasshouse"}]'
    ports:
    - "8080:8080"
    networks:
      - webui-net
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
    volumes:
      - qdrant-storage:/qdrant/storage
    networks:
      - webui-net

  docling-serve:
    image: ghcr.io/docling-project/docling-serve-cu128:main
    container_name: docling-serve
    ports:
      - "5001:5001"
    environment:
      DOCLING_SERVE_MAX_SYNC_WAIT: 720
      DOCLING_SERVE_ENABLE_UI: "true"
      NVIDIA_VISIBLE_DEVICES: "all"
    runtime: nvidia
    restart: unless-stopped
    networks:
      - webui-net

  vllm-Qwen3-Reranker-06B:
    image: vllm/vllm-openai:v0.10.2
    container_name: vllm-Qwen3-Reranker-06B
    runtime: nvidia
    restart: unless-stopped
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "9001:9001"
    networks:
      - webui-net
    ipc: host
    command: |
      --model Qwen/Qwen3-Reranker-0.6B
      --gpu-memory-utilization 0.22
      --host 0.0.0.0
      --port 9001
      --max-model-len 16000
      --cpu-offload-gb 10
      --hf_overrides '{"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'  
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  vllm-gpt:
    image: vllm/vllm-openai:v0.10.2
    container_name: vllm-gpt
    runtime: nvidia
    restart: unless-stopped
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ports:
      - "9002:9002"
    networks:
      - webui-net
    ipc: host
    command: |
      --model openai/gpt-oss-20b
      --gpu-memory-utilization 0.6
      --host 0.0.0.0
      --port 9002
      --max-model-len 32000
      --max-num-seqs 128
      --async-scheduling
      --enable-auto-tool-choice
      --tool-call-parser openai
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - TZ=Europe/Istanbul
    command: --schedule "0 0 0 * * *" open-webui docling-serve searxng portainer

  searxng:
    image: docker.io/searxng/searxng:latest
    container_name: searxng
    volumes:
      - /root/searxng:/etc/searxng:rw
    ports:
      - 4000:4000
    networks:
      - webui-net
    restart: unless-stopped

volumes:
  open-webui-data:
  qdrant-storage:

networks:
  webui-net:
    name: webui-net